{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd \n",
    "import os \n",
    "from loaddata import MultiModalLoader\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "from model import MultistainModel\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from torchmetrics import AUROC\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = \"data/datatable.csv\"\n",
    "filepath= \"results\"\n",
    "\n",
    "n_mods = 3\n",
    "n_epochs = 2\n",
    "\n",
    "train_DS = MultiModalLoader(f, \"TRAIN\",n_mods=n_mods)\n",
    "test_DS = MultiModalLoader(f, \"TEST\",n_mods=n_mods)\n",
    "valid_DS = MultiModalLoader(f, \"VALIDATION\",n_mods=n_mods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_DS, batch_size=32, shuffle=True)\n",
    "valid_loader = DataLoader(valid_DS, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_DS, batch_size=32, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()\n",
    "\n",
    "model = MultistainModel(n_classes = 2)\n",
    "#model = torch.compile(premodel)  # TODO not working yet \n",
    "criterion = nn.CrossEntropyLoss()  \n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)  # TODO optimal optimizer for this task?\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma = 0.9)  # TODO optimal scheduler? \n",
    "auroc = AUROC(task=\"multilabel\", num_labels=2)  # TODO do for categorical\n",
    "activate = nn.Softmax(dim=1)  # TODO for catefgorical needs to be a softmax\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.randn(1,3,3,224, 224)\n",
    "\n",
    "# Define the SummaryWriter object\n",
    "writer = SummaryWriter()\n",
    "\n",
    "# Add the graph of the model to TensorBoard\n",
    "writer.add_graph(model, inputs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1|Train:   2%|▏         | 1/44 [01:11<50:56, 71.08s/batch, train_AUROC=0.477, train_loss=0.735]\n",
      "Epoch 1|Valid:  14%|█▍        | 1/7 [00:30<03:05, 30.96s/batch, valid_AUROC=0.301, valid_loss=0.703]\n",
      "Epoch 2|Train:   2%|▏         | 1/44 [00:59<39:22, 54.95s/batch, train_AUROC=0.627, train_loss=0.704]"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    train_loss = []\n",
    "    train_auroc = []\n",
    "    with tqdm(train_loader, unit=\"batch\") as tepoch:\n",
    "        for idx,(x, y) in enumerate(tepoch):\n",
    "            tepoch.set_description(f\"Epoch {epoch+1}|Train\")\n",
    "\n",
    "            pred = model(x)\n",
    "            loss = criterion(pred,y.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            tr_auroc = auroc(activate(pred), y.int())\n",
    "\n",
    "            train_loss.append(loss.item())\n",
    "            train_auroc.append(tr_auroc)\n",
    "            tepoch.set_postfix(train_loss=loss.item(), train_AUROC=tr_auroc.item())\n",
    "\n",
    "            writer.add_scalar('training_loss', loss.item(), global_step=epoch * len(train_loader) + idx)\n",
    "            writer.add_scalar('training_auroc', tr_auroc.item(), global_step=epoch * len(train_loader) + idx)\n",
    "\n",
    "            for name, param in model.named_parameters():\n",
    "                writer.add_histogram(name, param, global_step=epoch * len(train_loader) + idx)\n",
    "            if idx>0:  # get rid of before running \n",
    "                break\n",
    "    mean_train_loss = np.mean(train_loss)  \n",
    "    mean_train_auroc = np.mean(train_auroc) \n",
    "\n",
    "    scheduler.step()\n",
    "    valid_loss = []\n",
    "    valid_auroc = []\n",
    "    model.eval()\n",
    "    with tqdm(valid_loader, unit=\"batch\") as vepoch:\n",
    "        for idx,(x, y) in enumerate(vepoch):\n",
    "            vepoch.set_description(f\"Epoch {epoch+1}|Valid\")\n",
    "            out = model(x)\n",
    "            \n",
    "            loss= criterion(out,y.float())\n",
    "            val_auroc  = auroc(activate(out), y.int())\n",
    "            \n",
    "            valid_loss.append(loss.item())\n",
    "            valid_auroc.append(val_auroc)\n",
    "            vepoch.set_postfix(valid_loss=loss.item(), valid_AUROC=val_auroc.item())\n",
    "\n",
    "            writer.add_scalar('validation_loss', loss.item(), global_step=idx)\n",
    "            writer.add_scalar('validation_auroc', val_auroc.item(), global_step=idx)\n",
    "\n",
    "\n",
    "            if idx>0: # TODO get rid of before running \n",
    "                break\n",
    "\n",
    "    mean_valid_loss = np.mean(valid_loss)  \n",
    "    mean_valid_auroc = np.mean(valid_auroc) \n",
    "\n",
    "\n",
    "writer.close()\n",
    "\n",
    "state = {\n",
    "    'epoch': epoch,\n",
    "    'state_dict': model.state_dict(),\n",
    "    'optimizer': optimizer.state_dict(),\n",
    "    }\n",
    "torch.save(state, filepath+\"/model.pt\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = []\n",
    "test_aurocs = []\n",
    "model.eval()\n",
    "results = []\n",
    "with tqdm(test_loader, unit=\"batch\") as testepoch:\n",
    "    for idx,(x, y) in enumerate(testepoch):\n",
    "        testepoch.set_description(f\"Test\")\n",
    "        out = model(x)\n",
    "        \n",
    "        loss = criterion(out,y.float())\n",
    "        test_auroc = auroc(activate(out), y.int())\n",
    "\n",
    "        results.append( torch.cat((y.float(),activate(out)),dim=1) )\n",
    "        \n",
    "        test_loss.append(loss.item())\n",
    "        test_aurocs.append(test_auroc.item())\n",
    "        testepoch.set_postfix(test_loss=loss.item(), test_AUROC=val_auroc.item())\n",
    "\n",
    "\n",
    "        if idx>0: # TODO get rid of before running \n",
    "            break\n",
    "\n",
    "    mean_test_loss = np.mean(test_loss)  # TODO save in tensorboard\n",
    "    mean_test_auroc = np.mean(test_aurocs)  # TODO save in tensorboard\n",
    "    results_df = pd.DataFrame(torch.cat(results).detach().numpy(),columns=[\"cls1_label\",\"cls2_label\",\"cls1_label\",\"cls2_pred\"])  # hardcoded for 2 classes only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.path.exists(filepath)\n",
    "if not os.path.exists(filepath):\n",
    "    os.mkdir(filepath)\n",
    "f = results_df.to_csv((filepath+\"/result_table.csv\"))\n",
    "#  TODO settings store as file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device =torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Devicetype {device.type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "52dfdb52af05ed8ca9c14e4bb1a5c208767ec70ca1bab18b877a8566669311bf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
